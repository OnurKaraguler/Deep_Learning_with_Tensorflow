{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ongoing-transsexual",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Eager mode uses the CPU. Switching to the CPU.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.compiler.mlcompute import mlcompute\n",
    "mlcompute.set_mlc_device(device_name='gpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-consultation",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "## 1.Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "honey-navigator",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Sequential, Input\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# from tensorflow.keras import Sequential, Input, Model\n",
    "# from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, BatchNormalization, Dropout, LSTM\n",
    "# from tensorflow.keras.losses import BinaryCrossentropy\n",
    "# from tensorflow.keras.metrics import (BinaryAccuracy, Precision, Recall, AUC, RootMeanSquaredError,\n",
    "#                                       FalsePositives, FalseNegatives, TruePositives, TrueNegatives)\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.activations import relu\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenging-willow",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "## 2.Read CSV files into DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary-above",
   "metadata": {},
   "source": [
    "You are provided with daily historical sales data. The task is to forecast the total amount of products sold in every shop for the test set. Note that the list of shops and products slightly changes every month. Creating a robust model that can handle such situations is part of the challenge.<br>\n",
    "\n",
    "\n",
    "<h3>File descriptions</h3>\n",
    "    <ul>\n",
    "        <li>sales_train.csv - the training set. Daily historical data from January 2013 to October 2015.</li>\n",
    "        <li>test.csv - the test set. You need to forecast the sales for these shops and products for November 2015.</li>\n",
    "        <li>sample_submission.csv - a sample submission file in the correct format.</li>\n",
    "        <li>items.csv - supplemental information about the items/products.</li>\n",
    "        <li>item_categories.csv  - supplemental information about the items categories.</li>\n",
    "        <li>shops.csv- supplemental information about the shops.</li>\n",
    "    </ul>\n",
    "            \n",
    "<h3>Data fields</h3>\n",
    "    <ul>\n",
    "        <li>ID - an Id that represents a (Shop, Item) tuple within the test set</li>\n",
    "        <li>shop_id - unique identifier of a shop</li>\n",
    "        <li>item_id - unique identifier of a product</li>\n",
    "        <li>item_category_id - unique identifier of item category</li>\n",
    "        <li>item_cnt_day - number of products sold. You are predicting a monthly amount of this measure</li>\n",
    "        <li>item_price - current price of an item</li>\n",
    "    <li>date - date in format dd/mm/yyyy</li>\n",
    "    <li>date_block_num - a consecutive month number, used for convenience. January 2013 is 0, February 2013 is 1,..., October 2015 is 33</li>\n",
    "    <li>item_name - name of item</li>\n",
    "    <li>shop_name - name of shop</li>\n",
    "    <li>item_category_name - name of item category</li>\n",
    "    <li>This dataset is permitted to be used for any purpose, including commercial use.</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "viral-ireland",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../Machine_Learning_with_Scikit_Learn/datasets/predict-future-sales/sales_train.csv\")\n",
    "test = pd.read_csv(\"../Machine_Learning_with_Scikit_Learn/datasets/predict-future-sales/test.csv\")\n",
    "\n",
    "\n",
    "# submission = pd.read_csv(common_path+'/sample_submission.csv')\n",
    "# items = pd.read_csv(common_path+'/items.csv')\n",
    "# item_cats = pd.read_csv(common_path+'/item_categories.csv')\n",
    "# shops = pd.read_csv(common_path+'/shops.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-richmond",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "## 3.Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-abuse",
   "metadata": {},
   "source": [
    "<a id='31'></a>\n",
    "### 3.1. Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-trance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-greece",
   "metadata": {},
   "source": [
    "<a id='32'></a>\n",
    "### 3.2. Drop unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-coffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped = train.drop(['date','item_price'], axis=1)\n",
    "df_dropped.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-iraqi",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecast_dropped = test.drop(['ID'], axis=1)\n",
    "df_forecast_dropped.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-demand",
   "metadata": {},
   "source": [
    "<a id='33'></a>\n",
    "### 3.3 Check zero variance features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-basement",
   "metadata": {},
   "outputs": [],
   "source": [
    "### It will zero variance features\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "var_thres=VarianceThreshold(threshold=0)\n",
    "var_thres.fit(df_dropped)\n",
    "df_dropped.columns[var_thres.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operational-ballet",
   "metadata": {},
   "outputs": [],
   "source": [
    "constant_columns = [column for column in df_dropped.columns\n",
    "                    if column not in df_dropped.columns[var_thres.get_support()]]\n",
    "\n",
    "print(len(constant_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separated-omega",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped = df_dropped.drop(constant_columns,axis=1)\n",
    "df_dropped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-mainland",
   "metadata": {},
   "source": [
    "<a id='34'></a>\n",
    "### 3.4 Check categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-enterprise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is no categorical columns in the dataframe\n",
    "categorical_feature_columns = list(set(df_dropped.columns) - set(df_dropped._get_numeric_data().columns))\n",
    "categorical_feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-uniform",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_feature_columns = list(df_dropped._get_numeric_data().columns)\n",
    "numerical_feature_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immune-celtic",
   "metadata": {},
   "source": [
    "<a id='35'></a>\n",
    "### 3.5 Investigate all the elements within each Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-microphone",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_dropped:\n",
    "    unique_vals = np.unique(df_dropped[col])\n",
    "    nr_values = len(unique_vals)\n",
    "    if nr_values < 10:\n",
    "        print(f'The number of values for feature {col} :{nr_values} -- {unique_vals}')\n",
    "    else:\n",
    "        print(f'The number of values for feature {col} :{nr_values}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powerful-deployment",
   "metadata": {},
   "source": [
    "<a id='36'></a>\n",
    "### 3.6 Create train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-moore",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group = df_dropped.groupby(['date_block_num', 'shop_id', 'item_id']).sum().reset_index()\n",
    "df_group.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "agreed-garage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>shop_id</th>\n",
       "      <th colspan=\"19\" halign=\"left\">item_cnt_day</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_block_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               item_id shop_id item_cnt_day                              ...  \\\n",
       "date_block_num                            0   1   2   3   4   5   6   7  ...   \n",
       "0                    0      54          NaN NaN NaN NaN NaN NaN NaN NaN  ...   \n",
       "1                    1      55          NaN NaN NaN NaN NaN NaN NaN NaN  ...   \n",
       "2                    2      54          NaN NaN NaN NaN NaN NaN NaN NaN  ...   \n",
       "3                    3      54          NaN NaN NaN NaN NaN NaN NaN NaN  ...   \n",
       "4                    4      54          NaN NaN NaN NaN NaN NaN NaN NaN  ...   \n",
       "\n",
       "                                                        \n",
       "date_block_num  24  25  26  27  28  29  30  31  32  33  \n",
       "0              NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "1              NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "2              NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "3              NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "4              NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pivot the dataframe and index with item_id and shop_id\n",
    "train = train.pivot_table(index=['item_id', 'shop_id'],\n",
    "                            values=['item_cnt_day'],\n",
    "                            columns='date_block_num', fill_value=0)\n",
    "#reset the index \n",
    "train = train.reset_index()\n",
    "#show \n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "outer-gospel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>(item_cnt_day, 0)</th>\n",
       "      <th>(item_cnt_day, 1)</th>\n",
       "      <th>(item_cnt_day, 2)</th>\n",
       "      <th>(item_cnt_day, 3)</th>\n",
       "      <th>(item_cnt_day, 4)</th>\n",
       "      <th>(item_cnt_day, 5)</th>\n",
       "      <th>(item_cnt_day, 6)</th>\n",
       "      <th>...</th>\n",
       "      <th>(item_cnt_day, 24)</th>\n",
       "      <th>(item_cnt_day, 25)</th>\n",
       "      <th>(item_cnt_day, 26)</th>\n",
       "      <th>(item_cnt_day, 27)</th>\n",
       "      <th>(item_cnt_day, 28)</th>\n",
       "      <th>(item_cnt_day, 29)</th>\n",
       "      <th>(item_cnt_day, 30)</th>\n",
       "      <th>(item_cnt_day, 31)</th>\n",
       "      <th>(item_cnt_day, 32)</th>\n",
       "      <th>(item_cnt_day, 33)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5320</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5233</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5232</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5268</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  shop_id  item_id  (item_cnt_day, 0)  (item_cnt_day, 1)  \\\n",
       "0   0        5     5037                NaN                NaN   \n",
       "1   1        5     5320                NaN                NaN   \n",
       "2   2        5     5233                NaN                NaN   \n",
       "3   3        5     5232                NaN                NaN   \n",
       "4   4        5     5268                NaN                NaN   \n",
       "\n",
       "   (item_cnt_day, 2)  (item_cnt_day, 3)  (item_cnt_day, 4)  (item_cnt_day, 5)  \\\n",
       "0                NaN                NaN                NaN                NaN   \n",
       "1                NaN                NaN                NaN                NaN   \n",
       "2                NaN                NaN                NaN                NaN   \n",
       "3                NaN                NaN                NaN                NaN   \n",
       "4                NaN                NaN                NaN                NaN   \n",
       "\n",
       "   (item_cnt_day, 6)  ...  (item_cnt_day, 24)  (item_cnt_day, 25)  \\\n",
       "0                NaN  ...                 1.0                 NaN   \n",
       "1                NaN  ...                 NaN                 NaN   \n",
       "2                NaN  ...                 NaN                 NaN   \n",
       "3                NaN  ...                 NaN                 NaN   \n",
       "4                NaN  ...                 NaN                 NaN   \n",
       "\n",
       "   (item_cnt_day, 26)  (item_cnt_day, 27)  (item_cnt_day, 28)  \\\n",
       "0                 NaN                 NaN                 1.0   \n",
       "1                 NaN                 NaN                 NaN   \n",
       "2                 NaN                 NaN                 1.5   \n",
       "3                 NaN                 NaN                 NaN   \n",
       "4                 NaN                 NaN                 NaN   \n",
       "\n",
       "   (item_cnt_day, 29)  (item_cnt_day, 30)  (item_cnt_day, 31)  \\\n",
       "0                 1.0                 1.0                 1.0   \n",
       "1                 NaN                 NaN                 NaN   \n",
       "2                 1.0                 NaN                 1.0   \n",
       "3                 NaN                 NaN                 1.0   \n",
       "4                 NaN                 NaN                 NaN   \n",
       "\n",
       "   (item_cnt_day, 32)  (item_cnt_day, 33)  \n",
       "0                 1.0                 NaN  \n",
       "1                 NaN                 NaN  \n",
       "2                 1.0                 1.0  \n",
       "3                 NaN                 NaN  \n",
       "4                 NaN                 NaN  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merge the train set and the test set \n",
    "dataset = pd.merge(test, train, on=['item_id', 'shop_id'], how='left')\n",
    "dataset = dataset.fillna(0)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "pediatric-trial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(item_cnt_day, 0)</th>\n",
       "      <th>(item_cnt_day, 1)</th>\n",
       "      <th>(item_cnt_day, 2)</th>\n",
       "      <th>(item_cnt_day, 3)</th>\n",
       "      <th>(item_cnt_day, 4)</th>\n",
       "      <th>(item_cnt_day, 5)</th>\n",
       "      <th>(item_cnt_day, 6)</th>\n",
       "      <th>(item_cnt_day, 7)</th>\n",
       "      <th>(item_cnt_day, 8)</th>\n",
       "      <th>(item_cnt_day, 9)</th>\n",
       "      <th>...</th>\n",
       "      <th>(item_cnt_day, 24)</th>\n",
       "      <th>(item_cnt_day, 25)</th>\n",
       "      <th>(item_cnt_day, 26)</th>\n",
       "      <th>(item_cnt_day, 27)</th>\n",
       "      <th>(item_cnt_day, 28)</th>\n",
       "      <th>(item_cnt_day, 29)</th>\n",
       "      <th>(item_cnt_day, 30)</th>\n",
       "      <th>(item_cnt_day, 31)</th>\n",
       "      <th>(item_cnt_day, 32)</th>\n",
       "      <th>(item_cnt_day, 33)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   (item_cnt_day, 0)  (item_cnt_day, 1)  (item_cnt_day, 2)  (item_cnt_day, 3)  \\\n",
       "0                NaN                NaN                NaN                NaN   \n",
       "1                NaN                NaN                NaN                NaN   \n",
       "2                NaN                NaN                NaN                NaN   \n",
       "3                NaN                NaN                NaN                NaN   \n",
       "4                NaN                NaN                NaN                NaN   \n",
       "\n",
       "   (item_cnt_day, 4)  (item_cnt_day, 5)  (item_cnt_day, 6)  (item_cnt_day, 7)  \\\n",
       "0                NaN                NaN                NaN                NaN   \n",
       "1                NaN                NaN                NaN                NaN   \n",
       "2                NaN                NaN                NaN                NaN   \n",
       "3                NaN                NaN                NaN                NaN   \n",
       "4                NaN                NaN                NaN                NaN   \n",
       "\n",
       "   (item_cnt_day, 8)  (item_cnt_day, 9)  ...  (item_cnt_day, 24)  \\\n",
       "0                NaN                NaN  ...                 1.0   \n",
       "1                NaN                NaN  ...                 NaN   \n",
       "2                NaN                NaN  ...                 NaN   \n",
       "3                NaN                NaN  ...                 NaN   \n",
       "4                NaN                NaN  ...                 NaN   \n",
       "\n",
       "   (item_cnt_day, 25)  (item_cnt_day, 26)  (item_cnt_day, 27)  \\\n",
       "0                 NaN                 NaN                 NaN   \n",
       "1                 NaN                 NaN                 NaN   \n",
       "2                 NaN                 NaN                 NaN   \n",
       "3                 NaN                 NaN                 NaN   \n",
       "4                 NaN                 NaN                 NaN   \n",
       "\n",
       "   (item_cnt_day, 28)  (item_cnt_day, 29)  (item_cnt_day, 30)  \\\n",
       "0                 1.0                 1.0                 1.0   \n",
       "1                 NaN                 NaN                 NaN   \n",
       "2                 1.5                 1.0                 NaN   \n",
       "3                 NaN                 NaN                 NaN   \n",
       "4                 NaN                 NaN                 NaN   \n",
       "\n",
       "   (item_cnt_day, 31)  (item_cnt_day, 32)  (item_cnt_day, 33)  \n",
       "0                 1.0                 1.0                 NaN  \n",
       "1                 NaN                 NaN                 NaN  \n",
       "2                 1.0                 1.0                 1.0  \n",
       "3                 1.0                 NaN                 NaN  \n",
       "4                 NaN                 NaN                 NaN  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop  some columns \n",
    "dataset.drop(['shop_id', 'item_id', 'ID'], axis=1,inplace=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hundred-collective",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((214200, 33, 1), (214200, 1), (214200, 33, 1))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#splitting the dataset \n",
    "X_train = np.expand_dims(dataset.values[:, :-1], axis=2)\n",
    "y_train = dataset.values[:, -1:]\n",
    "X_test = np.expand_dims(dataset.values[:, 1:], axis=2)\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "rotary-fight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 64)                16896     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 16,961\n",
      "Trainable params: 16,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#buid LSTM Network \n",
    "model = Sequential()\n",
    "model.add(LSTM(units=64, input_shape=(33, 1)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse',\n",
    "              optimizer='adam',\n",
    "              metrics=['mean_squared_error'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "reserved-density",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "   5/6694 [..............................] - ETA: 1:28:09 - loss: nan - mean_squared_error: nan"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-48be7b52ad09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(X_train, y_train,\n\u001b[0m\u001b[1;32m      2\u001b[0m                     epochs=10)\n",
      "\u001b[0;32m~/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/ml/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backed-neighbor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-meeting",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-worry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = df_group.pivot_table(index=['shop_id','item_id'], columns='date_block_num', values='item_cnt_day', \n",
    "#                         fill_value=0)\n",
    "# df_train.reset_index(inplace=True)\n",
    "\n",
    "# df_test = pd.merge(df_forecast_dropped, df_train, on=['shop_id','item_id'], how='left').fillna(0)\n",
    "\n",
    "# df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "balanced-craft",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "## 4. Regressions and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technological-spice",
   "metadata": {},
   "source": [
    "<a id='41'></a>\n",
    "### 4.1 Split the data into X & y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "potential-louisville",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train[df_train.columns[:-1]]\n",
    "y = df_train[df_train.columns[-1:]]\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-cornell",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size = 0.8, test_size=0.15, random_state=15)\n",
    "\n",
    "X_test = df_test.values[:, 1:]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train).reshape(-1, 35, 1)\n",
    "X_valid = scaler.fit_transform(X_valid).reshape(-1, 35, 1)\n",
    "X_test = scaler.fit_transform(X_test).reshape(-1, 35, 1)\n",
    "\n",
    "# X_train1 = X_train1.reshape(-1, 35, 1)\n",
    "# X_valid1 = X_valid1.reshape(-1, 35, 1)\n",
    "# X_test1 = X_test1.reshape(-1, 35, 1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-transsexual",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#buid LSTM Network \n",
    "model = Sequential()\n",
    "model.add(LSTM(units=64, input_shape=(None, 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse',\n",
    "              optimizer='adam',\n",
    "              metrics=['mean_squared_error'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-closer",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model = Sequential([\n",
    "#     LSTM(30, return_sequences=True, input_shape=[None, 1]),\n",
    "#     LSTM(30, return_sequences=True),\n",
    "#     LSTM(30),\n",
    "#     Dense(1)\n",
    "# ])\n",
    "\n",
    "# model.compile(optimizer=Adam(learning_rate=0.0005), \n",
    "#               loss = 'mse',\n",
    "#               metrics=[RootMeanSquaredError(name='rmse')])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-consciousness",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "   5/6694 [..............................] - ETA: 1:29:27 - loss: nan - mean_squared_error: nan"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-stage",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-touch",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = prediction.clip(0, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-mambo",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "political-oliver",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinguished-flower",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-criterion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metropolitan-oracle",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# history = model.fit(X_train, y_train, epochs=5,\n",
    "#                     validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-freight",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped = df_dropped.drop(constant_columns,axis=1)\n",
    "df_dropped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-greeting",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-taylor",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = prediction.clip(0, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepted-protein",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compressed-differential",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-insured",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weird-measure",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imported-telescope",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-tactics",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'ID': df_test_first['ID'], 'item_cnt_month': prediction[:,0].reshape(-1)})\n",
    "#submission['item_cnt_month'] = submission['item_cnt_month'].round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earlier-patient",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-intersection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the submission csv to make sure it's in the right format\n",
    "submissions_check = pd.read_csv(\"submission.csv\")\n",
    "submissions_check.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-ceremony",
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions_check['item_cnt_month'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-doubt",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-irrigation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-antigua",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
